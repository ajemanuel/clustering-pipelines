{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = 'Z:/HarveyLab/Alan/Data/20171002/p3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(dataPath)\n",
    "import sys\n",
    "kwikToolsPath = 'C://Users/Alan/Documents/Github/kwik-tools'\n",
    "sys.path.append(kwikToolsPath)\n",
    "import read_rhd as rhd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from shutil import copy2\n",
    "import datetime\n",
    "import subprocess\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Files:\n",
      "gridIndent_171002_180119.rhd\n",
      "gridIndent_171002_180134.rhd\n",
      "gridIndent_171002_180149.rhd\n",
      "gridIndent_171002_180204.rhd\n",
      "gridIndent_171002_180219.rhd\n",
      "gridIndent_171002_180234.rhd\n",
      "gridIndent_171002_180249.rhd\n",
      "gridIndent_171002_180305.rhd\n",
      "gridIndent_171002_180321.rhd\n",
      "gridIndent_171002_180336.rhd\n",
      "gridIndent_171002_180351.rhd\n",
      "gridIndent_171002_180406.rhd\n",
      "gridIndent_171002_180421.rhd\n",
      "gridIndent_171002_180436.rhd\n",
      "gridIndent_171002_180451.rhd\n",
      "gridIndent_171002_180506.rhd\n",
      "gridIndent_171002_180521.rhd\n",
      "gridIndent_171002_180537.rhd\n",
      "gridIndent_171002_180552.rhd\n",
      "gridIndent_171002_180607.rhd\n",
      "gridIndent_171002_180622.rhd\n",
      "gridIndent_171002_180637.rhd\n",
      "gridIndent_171002_180652.rhd\n",
      "gridIndent_171002_180707.rhd\n",
      "gridIndent_171002_180722.rhd\n",
      "gridIndent_171002_180738.rhd\n",
      "gridIndent_171002_180753.rhd\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('*.rhd')\n",
    "#for x in files:\n",
    "#    print(x)\n",
    "files.sort(key=os.path.getmtime)  ## this sorting may be OS sensitive\n",
    "print('Sorted Files:')\n",
    "for x in files:\n",
    "    print(x)\n",
    "    \n",
    "basename = os.path.basename(dataPath) # taking foldername as basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#batch write .rhd to .dat\n",
    "for file in files:\n",
    "    d = rhd.read_rhd(file)\n",
    "    recordings = np.transpose(d['amplifier_data'])\n",
    "    stimulation = ()\n",
    "    #save amplifier data as .dat\n",
    "    recordings.tofile(os.path.splitext(file)[0] +'.dat')  \n",
    "    #save digital input streams\n",
    "    for digitalChannel in range(d['board_dig_in_data'].shape[0]):\n",
    "        d['board_dig_in_data'][digitalChannel].tofile(os.path.splitext(file)[0] + 'chan' + str(digitalChannel) + '.di')\n",
    "    #save analog input streams\n",
    "    for analogChannel in range(d['aux_input_data'].shape[0]):\n",
    "        d['aux_input_data'][analogChannel].tofile(os.path.splitext(file)[0] + 'chan' + str(analogChannel) + '.ai')\n",
    "\n",
    "#create .prm file and copy .prb file to data directory    \n",
    "datFiles = glob.glob(basename + '*.dat')\n",
    "datFiles.sort(key=os.path.getmtime)\n",
    "\n",
    "prb_file = 'A1x32-Poly2-5mm-50s-177-A32.prb' #prb_file = 'Buzsaki32.prb'\n",
    "copy2(kwikToolsPath+'/'+prb_file,dataPath)\n",
    "\n",
    "\n",
    "with open(basename + '.prm', \"w\") as text_file:\n",
    "        text_file.write('experiment_name = \\'{0}\\' \\n'.format(basename))\n",
    "        text_file.write('prb_file = \\'{0}\\'\\n'.format(prb_file)) \n",
    "        text_file.write('traces = dict( \\n')\n",
    "        text_file.write('\\traw_data_files={0},\\n'.format(datFiles))\n",
    "        text_file.write('\\tvoltage_gain={0}.0,\\n'.format(192))  #from Intan RHD2000 documentation\n",
    "        text_file.write('\\tsample_rate={0},\\n'.format(d['frequency_parameters']['amplifier_sample_rate']))\n",
    "        text_file.write('\\tn_channels={0},\\n'.format(len(d['amplifier_channels'])))\n",
    "        text_file.write('\\tdtype=\\'uint16\\'\\n')\n",
    "        text_file.write('\\t)\\n\\n')\n",
    "        \n",
    "        text_file.write('spikedetekt = dict(\\n')\n",
    "        text_file.write('\\tfilter_low=500.,\\n') # low pass filter? (as documented in phy)\n",
    "        text_file.write('\\tfilter_high_factor=0.95 * .5,\\n') # high pass filter (as documented in phy)\n",
    "        text_file.write('\\tfilter_butter_order=3,\\n') # order of Butterworth Filter\n",
    "        text_file.write('\\n')\n",
    "        text_file.write('\\tfilter_lfp_low=20,\\n') # LFP filter low-pass frequency\n",
    "        text_file.write('\\tfilter_lfp_high=0,\\n') #LFP filter high-pass frequency\n",
    "        text_file.write('\\n')\n",
    "        text_file.write('\\tchunk_size_seconds=1,\\n')\n",
    "        text_file.write('\\tchunk_overlap_seconds=.015,\\n')\n",
    "        text_file.write('\\n')\n",
    "        text_file.write('\\tn_excerpts=50,\\n')\n",
    "        text_file.write('\\texcerpts_size_seconds=1,\\n')\n",
    "        text_file.write('\\tthreshold_strong_std_factor=5.5,\\n')\n",
    "        text_file.write('\\tthreshold_weak_std_factor=3.5,\\n')\n",
    "        text_file.write(\"\\tdetect_spikes='negative',\\n\")\n",
    "        text_file.write('\\n')\n",
    "        text_file.write('\\tconnected_component_join_size=1,\\n')\n",
    "        text_file.write('\\n')\n",
    "        text_file.write('\\textract_s_before=16,\\n')\n",
    "        text_file.write('\\textract_s_after=16,\\n')\n",
    "        text_file.write('\\n')\n",
    "        text_file.write('\\tn_features_per_channel=3,\\n') #number of features per channel\n",
    "        text_file.write('\\tpca_n_waveforms_max=10000,\\n')\n",
    "        text_file.write(')\\n')\n",
    "        text_file.write('\\n')\n",
    "        text_file.write('klustakwik2 = dict(\\n')\n",
    "        text_file.write('\\tnum_starting_clusters=100,\\n')\n",
    "        text_file.write(')\\n')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concatenate all .dat files for mda conversion for sorting with mountainsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Files:\n",
      "gridIndent_171002_180119.dat\n",
      "gridIndent_171002_180134.dat\n",
      "gridIndent_171002_180149.dat\n",
      "gridIndent_171002_180204.dat\n",
      "gridIndent_171002_180219.dat\n",
      "gridIndent_171002_180234.dat\n",
      "gridIndent_171002_180249.dat\n",
      "gridIndent_171002_180305.dat\n",
      "gridIndent_171002_180321.dat\n",
      "gridIndent_171002_180336.dat\n",
      "gridIndent_171002_180351.dat\n",
      "gridIndent_171002_180406.dat\n",
      "gridIndent_171002_180421.dat\n",
      "gridIndent_171002_180436.dat\n",
      "gridIndent_171002_180451.dat\n",
      "gridIndent_171002_180506.dat\n",
      "gridIndent_171002_180521.dat\n",
      "gridIndent_171002_180537.dat\n",
      "gridIndent_171002_180552.dat\n",
      "gridIndent_171002_180607.dat\n",
      "gridIndent_171002_180622.dat\n",
      "gridIndent_171002_180637.dat\n",
      "gridIndent_171002_180652.dat\n",
      "gridIndent_171002_180707.dat\n",
      "gridIndent_171002_180722.dat\n",
      "gridIndent_171002_180738.dat\n",
      "gridIndent_171002_180753.dat\n"
     ]
    }
   ],
   "source": [
    "datFiles = glob.glob('*.dat')\n",
    "#for x in datFiles:\n",
    "#    print(x)\n",
    "datFiles.sort(key=lambda files: files[-10:-4]) #key=os.path.getmtime\n",
    "print('Sorted Files:')\n",
    "for x in datFiles:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on file 0 of 27\n",
      "on file 1 of 27\n",
      "on file 2 of 27\n",
      "on file 3 of 27\n",
      "on file 4 of 27\n",
      "on file 5 of 27\n",
      "on file 6 of 27\n",
      "on file 7 of 27\n",
      "on file 8 of 27\n",
      "on file 9 of 27\n",
      "on file 10 of 27\n",
      "on file 11 of 27\n",
      "on file 12 of 27\n",
      "on file 13 of 27\n",
      "on file 14 of 27\n",
      "on file 15 of 27\n",
      "on file 16 of 27\n",
      "on file 17 of 27\n",
      "on file 18 of 27\n",
      "on file 19 of 27\n",
      "on file 20 of 27\n",
      "on file 21 of 27\n",
      "on file 22 of 27\n",
      "on file 23 of 27\n",
      "on file 24 of 27\n",
      "on file 25 of 27\n",
      "on file 26 of 27\n",
      "use this as second dimension when converting to mda file using mdaconvert 6487920\n"
     ]
    }
   ],
   "source": [
    "## Concatenate dat files prior to mda conversion\n",
    "\n",
    "allData = np.array([])\n",
    "numFiles = len(datFiles)\n",
    "\n",
    "for i, file in enumerate(datFiles):\n",
    "        print('on file',i,'of',numFiles)\n",
    "        allData = np.concatenate((allData, np.fromfile(file)))\n",
    "        \n",
    "if not os.path.exists(dataPath+'/alldata'):\n",
    "    os.mkdir(dataPath+'/alldata')\n",
    "\n",
    "allData.tofile(dataPath+'/alldata/raw.dat')\n",
    "\n",
    "# use this as second dimension when converting to mda file using mdaconvert\n",
    "print('use this as second dimension when converting to mda file using mdaconvert',int(len(allData)/8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C://Users/Alan/Desktop/UbuntuShare/20171008/p3/raw.dat'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy data to Ubuntu share\n",
    "\n",
    "dt = datetime.datetime.now()\n",
    "yearMonthDay = \tdt.strftime('%Y%m%d')  \n",
    "UbuntuSharePath = 'C://Users/Alan/Desktop/UbuntuShare/'+yearMonthDay+'/'+basename+'/'\n",
    "\n",
    "if not os.path.exists(UbuntuSharePath):\n",
    "    os.makedirs(UbuntuSharePath)\n",
    "copy2(dataPath+'/alldata/raw.dat',UbuntuSharePath) ## copies raw.dat to UbuntuShare folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## define functions for writing and running shell script in Ubuntu virtualbox\n",
    "\n",
    "def writeUbuntuShell(UbuntuSharePath,basename, probe=None, num_channels=32):\n",
    "    '''\n",
    "    UbuntuSharePath is path of path that is shared with Ubuntu Virtualbox\n",
    "    basename is the string of the containing folder\n",
    "    probe is shorthand for a probe: 'poly2' for A1x32-Poly2-5mm-50s-177-A32\n",
    "    \n",
    "    Returns: string of Ubuntu location of shell\n",
    "    '''\n",
    "    oldpath = os.getcwd()\n",
    "    os.chdir(UbuntuSharePath)\n",
    "    if probe == 'poly2': # if A1x32-Poly2-5mm-50s-177-A32\n",
    "        copy2('C://Users/Alan/Documents/Github/kwik-tools/poly2Geom.csv',UbuntuSharePath)\n",
    "        num_channels=32\n",
    "    dt = datetime.datetime.now()\n",
    "    yearMonthDay =     dt.strftime('%Y%m%d')  \n",
    "    sortDir = '/home/alan/data/sortProjects/'+yearMonthDay\n",
    "    sortDirFull = sortDir+'/datasets/'+basename ## make folder for sortProject with folder name as current date and basename as dataset\n",
    "\n",
    "\n",
    "    with open('datasets%s.txt' % (yearMonthDay) ,'a+') as datasetFile:\n",
    "        datasetFile.write(basename+' /datasets/'+basename+'\\n')\n",
    "    \n",
    "    with open('pipelines'+yearMonthDay+'.txt','a+') as pipelineFile:\n",
    "        pipelineFile.write('ms2alan ms2_alan.pipeline') # default mountainsort pipeline file\n",
    "    \n",
    "    with open('params%s.json' % (yearMonthDay) ,'w+') as paramFile:\n",
    "        if probe == None:\n",
    "            paramFile.write('{\"samplerate\":20000,\"sign\":-1}') # default sample rate is 20 kHz and usually see negative spikes\n",
    "        elif probe == 'poly2':\n",
    "            paramFile.write('{\"samplerate\":20000,\"sign\":-1,\"adjacency_radius\":100}')\n",
    "    with open('tempShell.sh', 'w+',newline='\\n') as shellfile:\n",
    "        shellfile.write('#! /bin/bash\\n')\n",
    "        shellfile.write('mkdir -p '+sortDirFull+'\\n')\n",
    "        \n",
    "        ## convert .dat to .mda, create prv, and copy to datasets\n",
    "        shellfile.write('cd /media/sf_UbuntuShare/%s/%s\\n' % (yearMonthDay,basename)) #directory of shared folder in Ubuntu Virtualbox\n",
    "        shellfile.write('/home/alan/mountainlab/bin/mdaconvert raw.dat raw.mda --dtype=uint16 --input_format=raw_timeseries --num_channels=%d\\n' % (num_channels)) # convert .dat to .mda\n",
    "        shellfile.write('/home/alan/mountainlab/bin/prv-create raw.mda\\n')\n",
    "        shellfile.write('cp /media/sf_UbuntuShare/%s/%s/raw.mda.prv %s\\n' % (yearMonthDay,basename,sortDirFull))\n",
    "        \n",
    "        ## copy params.json file to sortDirFull\n",
    "        \n",
    "        shellfile.write('cp params%s.json %s/params.json\\n' % (yearMonthDay,sortDirFull))\n",
    "        \n",
    "        if probe == 'poly2':\n",
    "            shellfile.write('cp poly2Geom.csv %s/geom.csv\\n' % (sortDirFull))\n",
    "\n",
    "        ## copy datasets.txt and pipelines.txt to sortDir\n",
    "        shellfile.write('cp datasets%s.txt %s/datasets.txt\\n' % (yearMonthDay,sortDir))\n",
    "        shellfile.write('cp pipelines%s.txt %s/pipelines.txt' % (yearMonthDay,sortDir))\n",
    "    os.chdir(oldpath)\n",
    "    return '/media/sf_UbuntuShare/%s/%s/tempShell.sh' % (yearMonthDay, basename)\n",
    "\n",
    "def runUbuntuShell(UbuntuShell):\n",
    "    '''\n",
    "    UbuntuShell is str with linux style directory of shell file\n",
    "        this directory is returned from the writeUbuntuShell function\n",
    "    For alan, that is something like /media/sf_UbuntuShare/DATE/DATABASE/shelltorun.sh\n",
    "    '''\n",
    "    with open('ubuntuRun.bat','w+') as file:\n",
    "        ## change directory to that with share folder\n",
    "        pathToVBOXmanage = '\"C:/Program Files/Oracle/VirtualBox/VBoxManage.exe\"'\n",
    "        file.write('title run ubuntu shell\\n')\n",
    "        ## start virtual box\n",
    "        file.write('call %s startvm \"Ubuntu\"\\n' %(pathToVBOXmanage))\n",
    "        ## i set up the virtualbox to set the RDONLYHOST property on setup\n",
    "        ## this wait command waits for that property to change before proceeding\n",
    "        file.write('call %s guestproperty wait \"Ubuntu\" RDONLYHOST\\n' %(pathToVBOXmanage))\n",
    "        ## executes the script UbuntuShell\n",
    "        file.write('call %s guestcontrol \"Ubuntu\" run --username alan --password 123ubuntubox --exe %s\\n' % (pathToVBOXmanage, UbuntuShell))\n",
    "    p = subprocess.Popen('ubuntuRun.bat',shell=True) #run the BAT file.\n",
    "    stdout, stderr = p.communicate()\n",
    "    return stdout, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ubuntuLocation = writeUbuntuShell(UbuntuSharePath,basename,'poly2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stdout, stderr = runUbuntuShell(ubuntuLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
